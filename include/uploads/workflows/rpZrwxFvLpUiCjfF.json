{
  "updatedAt": "2025-12-04T15:03:16.551Z",
  "createdAt": "2025-11-30T22:42:31.771Z",
  "id": "rpZrwxFvLpUiCjfF",
  "name": "first_prompt_generator_v3",
  "description": null,
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "sessionId"
            },
            {
              "name": "model_first"
            },
            {
              "name": "model_second"
            },
            {
              "name": "system_prompt_first"
            },
            {
              "name": "user_prompt"
            },
            {
              "name": "context"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -240,
        -84
      ],
      "id": "d24af8a6-f9a7-4537-b4b5-5f35a143fee1",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=User Prompt: {{ $json.user_prompt }}\n\n{{ $json.context !== 'None' ? 'Additional Context: ' + $json.context : '' }}\n\nTarget Model: {{ $json.model_second }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.system_prompt_first }}"
        }
      },
      "id": "f9f30637-ed68-44dd-a5e3-b8c74429fa30",
      "name": "Prompt Engineer Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        488,
        -432
      ],
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "model": "={{ $('Start').item.json.model_first }}",
        "options": {}
      },
      "id": "9444e078-7a7d-41bf-89c8-500a7e1a1018",
      "name": "Ollama Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        432,
        -208
      ],
      "credentials": {
        "ollamaApi": {
          "id": "Vy8Zgbfd9ejDpvxs",
          "name": "Ollama account"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $json.sessionId }}"
      },
      "id": "9bb3219a-bed5-4a13-9a00-fb8fbbf9531f",
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        560,
        -208
      ]
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n\t\"system_prompt_second\": {\n\t\t\"type\": \"string\"\n\t},\n\t\"user_intent\": {\n\t\t\"type\": \"string\"\n\t},\n\t\"key_requirements\": {\n\t\t\"type\": \"array\",\n\t\t\"items\": {\n\t\t\t\"type\": \"string\"\n\t\t}\n\t},\n\t\"optimization_notes\": {\n\t\t\"type\": \"string\"\n\t}\n}"
      },
      "id": "0912b0a9-ee40-412c-8fba-c6419285d726",
      "name": "Structured Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        688,
        -208
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "3882980e-0b1d-42aa-b4e3-12aa73865b04",
              "name": "system_prompt_second",
              "value": "={{ $json.output.system_prompt_second }}",
              "type": "string"
            },
            {
              "id": "3882980e-0b1d-42aa-b4e3-12aa73865b05",
              "name": "user_intent",
              "value": "={{ $json.output.user_intent }}",
              "type": "string"
            },
            {
              "id": "3882980e-0b1d-42aa-b4e3-12aa73865b06",
              "name": "key_requirements",
              "value": "={{ $json.output.key_requirements }}",
              "type": "string"
            },
            {
              "id": "3882980e-0b1d-42aa-b4e3-12aa73865b07",
              "name": "optimization_notes",
              "value": "={{ $json.output.optimization_notes }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1120,
        -424
      ],
      "id": "a33dbd23-fdc0-4478-928a-b802f2f75fd1",
      "name": "Return"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -688,
        -276
      ],
      "id": "69eba165-556c-4b4f-abe5-9dfc3b395ac5",
      "name": "When clicking 'Execute workflow'"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "92a5aa82-6066-4aa2-ac1f-b3f36dff02e7",
              "name": "sessionId",
              "value": "={{ Math.floor(Math.random() * 1e15) }}",
              "type": "string"
            },
            {
              "id": "9340ba64-fb11-4650-8899-dd035ca7a8ce",
              "name": "model_first",
              "value": "qwen2.5:3b",
              "type": "string"
            },
            {
              "id": "7269b5d6-31e9-4a46-bd4f-ecb05cdb1b4a",
              "name": "model_second",
              "value": "qwen2.5:3b",
              "type": "string"
            },
            {
              "id": "aae1e9a7-ab58-4f82-8284-723eecf307ac",
              "name": "user_prompt",
              "value": "How to use n8n to make an agent improve it's own system prompt",
              "type": "string"
            },
            {
              "id": "d534f635-9dcc-4076-aaa3-2fef8c6b6173",
              "name": "context",
              "value": "None",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -464,
        -276
      ],
      "id": "a76f39b2-c7e3-4225-8d1e-4292568894b8",
      "name": "Example Input"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "5da3db01-8500-4422-832d-d7d1adbea485",
              "name": "success",
              "value": false,
              "type": "boolean"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        896,
        -232
      ],
      "id": "a296f3bb-e3ff-4148-a55c-7a346135e9af",
      "name": "Error"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "498484c3-b469-43f1-88ef-f3a78d9f018f",
              "name": "success",
              "value": true,
              "type": "boolean"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        896,
        -424
      ],
      "id": "eb1e547c-18ba-4211-979a-08ce365db2ae",
      "name": "Success"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        -16,
        -180
      ],
      "id": "7943842a-5dc2-43e7-b276-5b9318539dc7",
      "name": "Start"
    },
    {
      "parameters": {
        "errorMessage": "Invalid input"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        552,
        -32
      ],
      "id": "620910e5-7c47-4227-80c8-86d30d35b1f1",
      "name": "Invalid input"
    },
    {
      "parameters": {
        "errorMessage": "={{ $json.error }}"
      },
      "type": "n8n-nodes-base.stopAndError",
      "typeVersion": 1,
      "position": [
        1120,
        -232
      ],
      "id": "f73d7e4d-155b-43f4-b400-83d1c8d87855",
      "name": "Error generating first prompt"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "3fc51ced-5d33-4d2e-8b8c-294cad2ef086",
              "leftValue": "={{ $json.sessionId }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "c0bb8e2b-907a-4dce-925d-68f622a9f54e",
              "leftValue": "={{ $json.model_first }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "e5885764-ee28-4481-8d91-637a47ba2553",
              "leftValue": "={{ $json.model_second }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "3152db6f-9d78-4d6d-ad53-989f8efcb517",
              "leftValue": "={{ $json.user_prompt }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "2f326d47-508d-421b-950e-7fe5cc7e9326",
              "leftValue": "={{ $json.system_prompt_first }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            },
            {
              "id": "a54bc2cd-b5ca-4c93-8c8b-3a6827057e50",
              "leftValue": "={{ $json.context }}",
              "rightValue": "",
              "operator": {
                "type": "string",
                "operation": "exists",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        208,
        -180
      ],
      "id": "3419208c-0fce-4443-8e64-90f4a0700809",
      "name": "Validate input"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "9c4eca86-a5da-4709-8bb3-37a7bbff4989",
              "name": "system_prompt_first",
              "value": "=You are an expert Prompt Engineer AI. Your job is to transform user requests into highly effective, optimized system prompts for a secondary AI agent.\n\n## CRITICAL: Output Format\n\n**You MUST respond with ONLY valid JSON. No markdown, no code blocks, no additional text.**\n\nYour response must be a single JSON object with exactly these 4 fields:\n\n```json\n{\n  \"system_prompt_second\": \"string\",\n  \"user_intent\": \"string\", \n  \"key_requirements\": [\"string\", \"string\", \"string\"],\n  \"optimization_notes\": \"string\"\n}\n```\n\n## Input Information\n\nYou will receive:\n- **User Prompt**: {{ $json.user_prompt }}\n- **Context**: {{ $json.context }} (may be \"None\")\n- **Target Model**: {{ $json.model_second }}\n\n## Your Task\n\nTransform the user's request into an optimized system prompt that the secondary AI agent will use to complete the task.\n\n## Prompt Engineering Principles\n\n### 1. Role & Objective\n- Start with a clear, specific role definition (e.g., \"You are a Python expert...\", \"You are a technical writer...\")\n- State the objective explicitly and concisely\n- Match the role to the task complexity and domain\n\n### 2. Context & Constraints\n- Include ALL relevant context from the user prompt\n- If context is not \"None\", integrate it naturally\n- Set clear boundaries (what to do, what NOT to do)\n- Specify any format requirements (e.g., \"respond in markdown\", \"use bullet points\")\n\n### 3. Task Structure\n- Break complex tasks into numbered steps\n- Use specific, actionable verbs (analyze, create, list, explain)\n- Provide success criteria when applicable\n- Include examples only if they clarify ambiguous requirements\n\n### 4. Model Optimization\n- **For smaller models** (< 7B): Keep instructions simple, use numbered lists, avoid complex reasoning chains\n- **For mid-size models** (7B-13B): Can handle moderate complexity, use structured formats\n- **For larger models** (> 13B): Can handle nuanced instructions, but still prefer clarity over cleverness\n- Always prefer explicit over implicit instructions\n\n## Output Schema\n\n### 1. `system_prompt_second` (string)\nThe complete, self-contained system prompt for the secondary agent. This should:\n- Be 100-300 words (concise but complete)\n- Start with role definition\n- Include all necessary context\n- Provide clear task structure\n- Specify output format if relevant\n\n### 2. `user_intent` (string)\nOne sentence summary of what the user wants to accomplish.\nExample: \"Create a Python function to parse CSV files with error handling\"\n\n### 3. `key_requirements` (array of 3-5 strings)\nCritical success factors for the task. Each should be specific and measurable.\nExamples:\n- \"Must handle files up to 100MB\"\n- \"Include type hints and docstrings\"\n- \"Explain trade-offs between approaches\"\n\n### 4. `optimization_notes` (string)\nBrief explanation (2-3 sentences) of how you tailored the prompt for the target model.\nFocus on: structure choices, complexity level, format decisions, or specific techniques used.\n\n## Examples\n\n### Example 1: Code Generation\n\n**Input**: \n- User Prompt: \"Create a REST API endpoint to search users\"\n- Context: \"Using FastAPI, PostgreSQL database\"\n- Target Model: \"qwen2.5:3b\"\n\n**Output**:\n```json\n{\n  \"system_prompt_second\": \"You are a Python backend developer expert in FastAPI. Create a REST API endpoint for user search with these requirements:\\n\\n1. Endpoint: GET /api/users/search\\n2. Query parameters: name (optional), email (optional), limit (default: 10)\\n3. Database: PostgreSQL using SQLAlchemy ORM\\n4. Return: JSON array of user objects with id, name, email\\n5. Include proper error handling and validation\\n6. Add type hints and a docstring\\n\\nProvide complete, production-ready code with explanations for key design decisions.\",\n  \"user_intent\": \"Build a FastAPI search endpoint for users with PostgreSQL backend\",\n  \"key_requirements\": [\"FastAPI framework\", \"PostgreSQL with SQLAlchemy\", \"Query parameters with validation\", \"Error handling\", \"Type hints and documentation\"],\n  \"optimization_notes\": \"Structured as numbered requirements for the 3B model. Specified exact endpoint path and return format to avoid ambiguity. Requested explanations to ensure the model demonstrates understanding.\"\n}\n```\n\n### Example 2: Content Writing\n\n**Input**:\n- User Prompt: \"Write a blog post about Docker best practices\"\n- Context: \"Target audience: intermediate developers, 800 words\"\n- Target Model: \"qwen2.5:3b\"\n\n**Output**:\n```json\n{\n  \"system_prompt_second\": \"You are a DevOps technical writer. Write an 800-word blog post on Docker best practices for intermediate developers. Structure:\\n\\n1. Introduction (100 words): Why container best practices matter\\n2. Image Optimization (250 words): Multi-stage builds, layer caching, .dockerignore\\n3. Security (250 words): Running as non-root, scanning images, secrets management\\n4. Production Readiness (150 words): Health checks, logging, resource limits\\n5. Conclusion (50 words): Summary and next steps\\n\\nUse practical examples. Maintain a professional but approachable tone. Include code snippets where relevant.\",\n  \"user_intent\": \"Create an educational blog post on Docker best practices for intermediate developers\",\n  \"key_requirements\": [\"800 words total\", \"Five-section structure\", \"Practical examples with code\", \"Intermediate skill level\", \"Professional tone\"],\n  \"optimization_notes\": \"Provided explicit word count per section to guide the model's pacing. Numbered structure helps the 3B model stay organized. Specified both technical depth (intermediate) and tone to calibrate the output style.\"\n}\n```\n\n## Critical Reminders\n\n1. **Preserve Intent**: Never change what the user is asking for, only optimize HOW it's communicated to the secondary agent\n2. **Include Context**: Always integrate the context field when it's not \"None\"\n3. **Be Specific**: Vague prompts produce vague results - use concrete, measurable criteria\n4. **JSON Only**: Your entire response must be the JSON object and nothing else\n5. **Target Model Matters**: Simpler models need simpler, more structured prompts\n\nNow, transform the provided user prompt into an optimized system prompt following this exact JSON format.\n",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -240,
        -276
      ],
      "id": "476a87e4-fef9-4e2c-8c20-bfcd4142f333",
      "name": "System prompt"
    }
  ],
  "connections": {
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Start",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt Engineer Agent": {
      "main": [
        [
          {
            "node": "Success",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Error",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Prompt Engineer Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "Prompt Engineer Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Prompt Engineer Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "When clicking 'Execute workflow'": {
      "main": [
        [
          {
            "node": "Example Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Example Input": {
      "main": [
        [
          {
            "node": "System prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Success": {
      "main": [
        [
          {
            "node": "Return",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Error": {
      "main": [
        [
          {
            "node": "Error generating first prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start": {
      "main": [
        [
          {
            "node": "Validate input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate input": {
      "main": [
        [
          {
            "node": "Prompt Engineer Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Invalid input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "System prompt": {
      "main": [
        [
          {
            "node": "Start",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "instanceId": "5477294f5d3a06ea145a32cfe84f2a422eac233f472a30914283db00ed658afe"
  },
  "pinData": {
    "When Executed by Another Workflow": [
      {
        "json": {
          "model": "qwen2.5:3b",
          "systemPrompt": "You are a Prompt Engineer AI. Your job is to create effective system prompts for another AI agent.|## Your TaskTransform the user's request into a clear, optimized system prompt for the target AI model.## Guidelines1. **Be Clear and Direct**   - Start with a clear role definition for the secondary agent   - Use precise, actionable language   - Break complex tasks into numbered steps   - Make instructions self-contained2. **Include Essential Context**   - Incorporate relevant background from the user's prompt   - Include the context information when it's not \"None\"   - Don't overwhelm with unnecessary details   - Focus on what the secondary agent needs to know3. **Structure for Success**   - Define clear objectives   - Specify output format when needed   - Set appropriate constraints and boundaries   - Include examples when they would be helpful   - Use formatting the model handles well4. **Optimize for Target Model**   - Match prompt style to the model's capabilities   - Keep instructions focused and concise   - Consider the model's strengths and limitations   - Use structure that aids comprehension## What to ProvideFor each prompt transformation, you must generate:1. **systemPrompt**: The complete system prompt that will be given to the secondary AI agent2. **userIntent**: A brief description of what the user is trying to accomplish3. **keyRequirements**: A list of the critical requirements for the task (3-5 items)4. **optimizationNotes**: Explanation of how you optimized this prompt for the target model## Important Rules- Always preserve the user's original intent completely- Include context information when it's provided- Make prompts self-contained and clear- Consider what output format would best serve the user's needs- Optimize your language and structure for the target model specified",
          "sessionId": "154724507088781",
          "prompt": "Ignore this",
          "context": "None"
        }
      }
    ]
  },
  "versionId": "cec0f199-01e2-42c2-af70-701f0b62a551",
  "activeVersionId": null,
  "versionCounter": 42,
  "triggerCount": 0,
  "tags": [
    {
      "updatedAt": "2025-11-30T21:32:53.614Z",
      "createdAt": "2025-11-30T21:32:53.614Z",
      "id": "6U6qptHGr1glwU73",
      "name": "level2"
    }
  ],
  "shared": [
    {
      "updatedAt": "2025-12-04T17:52:54.896Z",
      "createdAt": "2025-12-04T17:52:54.896Z",
      "role": "workflow:owner",
      "workflowId": "rpZrwxFvLpUiCjfF",
      "projectId": "G7MwyqNqY0Rnoh0q",
      "project": {
        "updatedAt": "2025-12-04T17:52:47.599Z",
        "createdAt": "2025-12-04T17:52:47.599Z",
        "id": "G7MwyqNqY0Rnoh0q",
        "name": "Unnamed Project",
        "type": "personal",
        "icon": null,
        "description": null
      }
    }
  ]
}